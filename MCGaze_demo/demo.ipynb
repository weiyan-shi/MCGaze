{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yrguan/anaconda3/envs/MCgaze/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = 0\n",
    "person_num = 0\n",
    "video_clip=None\n",
    "video_clip_set = []\n",
    "vid_len = len(os.listdir('MCGaze/MCGaze_demo/frames'))\n",
    "while frame_id < vid_len:\n",
    "    frame = cv2.imread('MCGaze/MCGaze_demo/frames/%d.jpg' % frame_id)\n",
    "    w,h,c = frame.shape\n",
    "    txt_path = 'MCGaze/MCGaze_demo/result/labels/%d.txt' % frame_id\n",
    "    f = open(txt_path, 'r')\n",
    "    #遍历每一行\n",
    "    face_bbox = []\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        line = line.split(' ')\n",
    "        for i in range(len(line)):\n",
    "            line[i] = eval(line[i])\n",
    "            #将每一行的数据存入字典\n",
    "        if line[0]==1:\n",
    "            face_bbox.append([(line[1]),(line[2]),(line[3]),(line[4])])\n",
    "    f.close()\n",
    "    #按第一维排序\n",
    "    if face_bbox is not None:\n",
    "        face_bbox = sorted(face_bbox, key= lambda x :x[0])\n",
    "        cur_person_num = len(face_bbox)\n",
    "    else:\n",
    "        cur_person_num = 0\n",
    "    if cur_person_num != person_num :\n",
    "        if video_clip==None:\n",
    "            video_clip={'frame_id': [], 'person_num': cur_person_num}\n",
    "            video_clip['frame_id'].append(frame_id)\n",
    "            for i in range(cur_person_num):\n",
    "                video_clip['p'+str(i)]=[face_bbox[i]]\n",
    "        else:\n",
    "            video_clip_set.append(video_clip)\n",
    "            video_clip={'frame_id': [], 'person_num': cur_person_num}\n",
    "            video_clip['frame_id'].append(frame_id)\n",
    "            for i in range(cur_person_num):\n",
    "                video_clip['p'+str(i)]=[face_bbox[i]]\n",
    "    else:\n",
    "        video_clip['frame_id'].append(frame_id)\n",
    "        for i in range(cur_person_num):\n",
    "                video_clip['p'+str(i)].append(face_bbox[i])\n",
    "    person_num = cur_person_num\n",
    "    frame_id += 1\n",
    "\n",
    "video_clip_set.append(video_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /data/yrguan/gaze/code/MCgaze/ckpts/multiclue_gaze_r50_l2cs.pth\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "import torch\n",
    "from mmcv.parallel import collate, scatter\n",
    "import numpy as np\n",
    "model = init_detector(\n",
    "        'MCGaze/configs/multiclue_gaze/multiclue_gaze_r50_l2cs.py',\n",
    "        'MCGaze/ckpts/multiclue_gaze_r50_l2cs.pth',\n",
    "        device=\"cuda:0\",\n",
    "        cfg_options=None,)\n",
    "cfg = model.cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'Resize', 'img_scale': (448, 448), 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.0}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img']}]\n"
     ]
    }
   ],
   "source": [
    "print(cfg.data.test.pipeline[1:])\n",
    "test_pipeline = Compose(cfg.data.test.pipeline[1:])\n",
    "\n",
    "def load_datas(data, test_pipeline, datas):\n",
    "    datas.append(test_pipeline(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yrguan/anaconda3/envs/MCgaze/lib/python3.9/site-packages/torch/tensor.py:447: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "def infer(datas,model,clip,i):\n",
    "    datas = sorted(datas, key=lambda x:x['img_metas'].data['filename']) # 按帧顺序 img名称从小到大\n",
    "    datas = collate(datas, samples_per_gpu=len(frame_id)) # 用来形成batch用的\n",
    "    datas['img_metas'] = datas['img_metas'].data\n",
    "    datas['img'] = datas['img'].data\n",
    "    datas = scatter(datas, [\"cuda:0\"])[0]\n",
    "    with torch.no_grad():\n",
    "        (det_bboxes, det_labels), det_gazes = model(\n",
    "                return_loss=False,\n",
    "                rescale=True,\n",
    "                format=False,# 返回的bbox既包含face_bboxes也包含head_bboxes\n",
    "                **datas)    # 返回的bbox格式是[x1,y1,x2,y2],根据return_loss函数来判断是forward_train还是forward_test.\n",
    "    gaze_dim = det_gazes['gaze_score'].size(1)\n",
    "    det_fusion_gaze = det_gazes['gaze_score'].view((det_gazes['gaze_score'].shape[0], 1, gaze_dim))\n",
    "    clip['gaze_p'+str(i)].append(det_fusion_gaze.cpu().numpy()) \n",
    "\n",
    "max_len = 100\n",
    "for clip in video_clip_set:\n",
    "    frame_id = clip['frame_id']\n",
    "    person_num = clip['person_num']\n",
    "    for i in range(person_num):\n",
    "        head_bboxes = clip['p'+str(i)]\n",
    "        clip['gaze_p'+str(i)] = []\n",
    "        datas = []\n",
    "        for j,frame in enumerate(frame_id):\n",
    "            cur_img = cv2.imread(\"MCGaze/MCGaze_demo/frames/\"+str(frame)+\".jpg\")\n",
    "            w,h,_ = cur_img.shape\n",
    "            for xy in head_bboxes[j]:\n",
    "                xy = int(xy)\n",
    "            head_center = [int(head_bboxes[j][1]+head_bboxes[j][3])//2,int(head_bboxes[j][0]+head_bboxes[j][2])//2]\n",
    "            l = int(max(head_bboxes[j][3]-head_bboxes[j][1],head_bboxes[j][2]-head_bboxes[j][0])*0.8)\n",
    "            head_crop = cur_img[max(0,head_center[0]-l):min(head_center[0]+l,w),max(0,head_center[1]-l):min(head_center[1]+l,h),:]\n",
    "            w_n,h_n,_ = head_crop.shape\n",
    "            # if frame==0:\n",
    "            #     plt.imshow(head_crop)\n",
    "            # print(head_crop.shape)\n",
    "            cur_data = dict(filename=j,ori_filename=111,img=head_crop,img_shape=(w_n,h_n,3),ori_shape=(2*l,2*l,3),img_fields=['img'])\n",
    "            load_datas(cur_data,test_pipeline,datas)\n",
    "            if len(datas)>max_len or j==(len(frame_id)-1):\n",
    "                infer(datas,model,clip,i)\n",
    "                datas = []\n",
    "                if j==(len(frame_id)-1):\n",
    "                    clip['gaze_p'+str(i)] = np.concatenate(clip['gaze_p'+str(i)],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid_clip in video_clip_set:\n",
    "    for i,frame_id in enumerate(vid_clip['frame_id']):  # 遍历每一帧\n",
    "        cur_img = cv2.imread(\"MCGaze/MCGaze_demo/frames/\"+str(vid_clip['frame_id'][i])+\".jpg\")\n",
    "        for j in range(vid_clip['person_num']):  # 遍历每一个人\n",
    "            gaze = vid_clip['gaze_p'+str(j)][i][0]\n",
    "            head_bboxes = vid_clip['p'+str(j)][i]\n",
    "            for xy in head_bboxes:\n",
    "                xy = int(xy)\n",
    "            head_center = [int(head_bboxes[1]+head_bboxes[3])//2,int(head_bboxes[0]+head_bboxes[2])//2]\n",
    "            l = int(max(head_bboxes[3]-head_bboxes[1],head_bboxes[2]-head_bboxes[0])*1)\n",
    "            gaze_len = l*1.0\n",
    "            thick = max(5,int(l*0.01))\n",
    "            cv2.arrowedLine(cur_img,(head_center[1],head_center[0]),\n",
    "                        (int(head_center[1]-gaze_len*gaze[0]),int(head_center[0]-gaze_len*gaze[1])),\n",
    "                        (230,253,11),thickness=thick)\n",
    "        cv2.imwrite('MCGaze/MCGaze_demo/new_frames/%d.jpg' % frame_id, cur_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 800)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('MCGaze/MCGaze_demo/new_frames/0.jpg')  #读取第一张图片\n",
    "fps = 25\n",
    "imgInfo = img.shape\n",
    "size = (imgInfo[1],imgInfo[0])  #获取图片宽高度信息\n",
    "print(size)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "videoWrite = cv2.VideoWriter('MCGaze/MCGaze_demo/new_video.mp4',fourcc,fps,size)# 根据图片的大小，创建写入对象 （文件名，支持的编码器，25帧，视频大小（图片大小））\n",
    " \n",
    "files = os.listdir('MCGaze/MCGaze_demo/new_frames/')\n",
    "out_num = len(files)\n",
    "for i in range(0,out_num):\n",
    "    fileName = 'MCGaze/MCGaze_demo/new_frames/'+str(i)+'.jpg'    #循环读取所有的图片,假设以数字顺序命名\n",
    "    img = cv2.imread(fileName)\n",
    " \n",
    "    videoWrite.write(img)# 将图片写入所创建的视频对象\n",
    "\n",
    "videoWrite.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCgaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
